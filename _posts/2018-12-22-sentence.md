---
layout: distill
permalink: /preview/sentence/
title: Sentence Segmentation and Why It Matters
description: Accompanying the paper &quot;<a href='https://example.com'>Where’s the Point? Self-Supervised Multilingual Punctuation-Agnostic Sentence Segmentation</a>&quot; with Jonas Pfeiffer and Ivan Vulić, accepted at ACL 2023.
giscus_comments: false
date: 2021-05-22

bibliography: 2018-12-22-distill.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
toc:
  - name: Introduction
  - name: Self-Supervised Sentence Segmentation
  - name: Where's the Point?
  - name: Conclusion
# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

{% include blog/sentence/prelude.html %}
{% include blog/sentence/main.html %}

<span id="introduction" style="padding-top: 4.8rem;">Sentences are fundamental to written language.</span> Naturally, Natural Language Processing often involves sentences. For example, the original BERT<d-cite key="devlin-etal-2019-bert"></d-cite> did Next *Sentence* Prediction, creation of the C4 corpus involved removing "any page with fewer than 5 *sentences*"<d-cite key="t5"></d-cite> and datasets such as MultiNLI<d-cite key="multinli"></d-cite> consist of annotated *sentence* pairs. In fact, around 72% of the papers in the ACL Anthology contain the word "sentence" (~16% in the abstract).<d-footnote>Checked using <a href="https://huggingface.co/datasets/ACL-OCL/acl-anthology-corpus">https://huggingface.co/datasets/ACL-OCL/acl-anthology-corpus</a> which as of May 2023 contains the papers until September 2022.</d-footnote> However, many of these say do not say what they mean by "sentence". BERT stands out by containing the following admission:

> Throughout this work, a “sentence” can be an arbitrary span of contiguous text, rather than an actual linguistic sentence.

Why do the authors concede all linguistic meaning of a sentence? And what do others mean when they say "sentence"? It's complicated. Attempts to define sentences go back at least 130 years to Henry Sweet's now-copied-all-over-textbooks definition<d-cite key="sweet2014new"></d-cite>:

> A sentence is a word or group of words capable of expressing a complete thought or meaning.

This definition is not really workable. It moves the problem to another term — what is a complete thought? There are chunks of text which most people would probably agree make up a sentence, but hardly convey a complete thought.<d-footnote>For example "Hey!", or "Look out!", or this notoriously jumbled sentence: <a href="https://www.snopes.com/fact-check/donald-trump-sentence">https://www.snopes.com/fact-check/donald-trump-sentence.</a></d-footnote> As such, when someone refers to "sentences" in NLP, they usually mean one of two things:

1. A chunk of text that resulted from instructing annotators to create a sentence, or to segment an existing text into sentences ("ground-truth sentences").
2. Predicted sentences from an automatic sentence segmentation tool, such as Punkt. Many of these are trained on ground-truth sentences.

The MultiNLI corpus is a collection of the first type. The filtering in the C4 corpus is an example of the second: it wouldn't be feasible to manually segment a large portion of the web into sentences. 

At first glance, it seems like we're good. If it's feasible, use ground-truth sentences created by human annotators. If not, approximate the ground-truth with an automatic sentence segmentation tool. But there are some problems.

__"Ground-truth" sentence boundaries are not objectively true.__

Many things involving language are subjective. It might seem like something as fundamental as sentence segmentation could  at least be solved objectively, but alas! There is plenty of room for interpretation in what to consider one sentence. Does nesting via quotation marks constitute a sentence boundary? What about parentheses, enumerations, colons, and semicolons? Different collections of sentences will have different styles of segmentation. <d-footnote>Style can also vary within a collection via different annotators or inconsistencies of an individual annotator.</d-footnote>

<style>
td {
    line-height: 1.5rem;
}
</style>

| <strong>Collection</strong>        | <strong>Sentences</strong>           |
| ------------- |:-------------|
| UD      | <span class="split" data-style="ud">This is the high season for tourism;</span><span class="split" data-style="ud"> between December and April few people visit and many tour companies and restaurants close down.</span> |
| OPUS100      | <span class="split" data-style="opus100">’I couldn’t help it,’ said Five, in a sulky tone; ’Seven jogged my elbow.’</span><span class="split" data-style="opus100">  On which Seven looked up and said, ’That’s right, Five! Always lay the blame (...)!’</span>      |
| Ersatz | <span class="split" data-style="ersatz">A lot of people would like to go back to 1970," before program trading, he said.</span><span class="split" data-style="ersatz"> "I would like to go back to 1970.</span><span class="split" data-style="ersatz"> But we’re not going back (...)"</span>      |

<p class="caption">Sentences in the UD<d-cite key="ud"></d-cite>, OPUS100<d-cite key="opus100"></d-cite> and Ersatz<d-cite key="ersatz"></d-cite> collections look noticeably different from each other.</p>

__It's hard to acquire ground-truth sentences for low-resource languages.__

Like any kind of labelled data, it's hard to get ground-truth sentences for the long tail of low-resource languages, which makes it hard to create sentence segmentation tools for these languages.

__Existing sentence segmentation tools rely on punctuation.__

Existing sentence segmentation tools like Ersatz<d-cite key="ersatz"></d-cite> and Punkt<d-cite key="punkt"></d-cite> rely on punctuation by treating sentence segmentation as a *disambiguation* task. They look at all punctuation characters in the text, and for each one, decide whether it constitutes a sentence boundary or not. This is a reasonable approach, but it falls apart in some cases. If a text is missing punctuation, it can not be segmented. Also, text in languages which do not use punctuation (most prominently Thai) can not be segmented.

> English: Many sentence segmentation tools rely on punctuation. That can be a problem in Thai.
>
> Thai: เครื่องมือแบ่งส่วนประโยคจำนวนมากใช้เครื่องหมายวรรคตอน นั่นอาจเป็นปัญหาในภาษาไทย
>

<hr class="my-3">

We tried to solve these issues by creating a *punctuation-agnostic*, *adaptible* sentence segmentation tool which can be trained without any ground-truth sentences via self-supervision.

## Self-Supervised Sentence Segmentation

Our key insight is that a model which is good at predicting the probability for a __new line (\n)__ to occur after any character can segment text into sentences. This could be a decoder-style model à la GPT<d-cite key="gpt"></d-cite> trained on next-character prediction. We use an encoder-style model trained with a newline-corruption method instead to use context from both sides of every character.<d-footnote>Details in <a href="https://example.com">Section 3 of the paper.</a></d-footnote> Like pretraining GPT models, this does not require any labelled data; it's just language modelling. 

The model learns how likely it is for any character to be followed by a new line. The predicted *newline probability* characterizes sentence boundaries: a new line can never occur within a sentence, while at the same time, a new line can generally occur after any sentence. This allows us to define sentences in a much more concrete way.

> Tired: A sentence is a word or group of words capable of expressing a complete thought or meaning.
>
> Wired: <strong style="color: var(--global-theme-color);">A sentence is any sequence of characters which could plausibly be followed by a newline.</strong>

Admittedly, the word "plausibly" still does a lot of heavy lifting here: we need a probability threshold to decide when to count a character as "plausibly followed by a newline". However, this threshold can just be set to a small constant value like 1%, where different thresholds give rise to different sets of sentences. 

{% include blog/sentence/threshold.html %}

In addition to not requiring any ground-truth sentences, this approach does not rely on punctuation, since we treat punctuation like any other character. 

But the problem of adaptability still remains. To solve this, we introduced an extension to the newline-prediction objective where we also predict the probability of punctuation characters like commas, dots, and quotation marks. This allows us to adapt the model to different styles of segmentation by learning a logistic regression over punctuation probabilities on a small amount of ground-truth sentences in the desired style of segmentation.<d-footnote>Details in <a href="https://example.com">Section 3.1 of the paper.</a></d-footnote>


{% include blog/sentence/styles.html %}

Why not just fine-tune the entire model? By learning only a handful of coefficients, the adaptation is more lightweight (127 parameters in our models) and interpretable (since every coefficient corresponds to a character).

<h2 id="where-s-the-point">Where's the Point?</h2>

You may now say, this is all well and good, but why bother with sentence segmentation at all? Many of today's language models are trained on individual sentences. As we've seen, different training datasets often give rise to different styles of sentence segmentation. It turns out that although the particular style of sentence segmentation may not be all that important, *consistency* between training and inference is important. That is, a model trained on a particular style of sentences performs best if text is segmented following the same style at inference time.

<div style="max-height: 40vw; align-items: center; display: flex; justify-content: center">
{% include blog/sentence/extrinsic_bars.svg %}
</div>

<p class="caption">Impact on BLEU score<d-cite key="bleu"></d-cite> of using our method to match sentence segmentation to the segmentation used during training of a Machine Translation model.<d-footnote>Details in <a href="https://example.com">Section 5 of the paper</a>.</d-footnote></p>

Having said that, there is recent work calling into question whether models (specifically for Machine Translation) should really be trained on individual sentences.<d-cite key="wicks-post-2022-sentence,sun-etal-2022-rethinking"></d-cite> I am not involved enough with Machine Translation to have a qualified opinion about this. I do, however, believe that sentences are sufficiently fundamental to language for there to always be a need for sentence segmentation tools, be it as a way to run inference of sentence-level models, as preprocessing step for datasets or as a user-facing feature.

## Conclusion

Sentence segmentation is interesting because it seems simple on the surface, but once you look more deeply, it turns out to be not-so-simple after all. It's also a textbook case for the immense challenge of multilinguality: in many languages, it's hard to find even a single ground-truth sentence, not to speak of any other kind of annotated data.

To simplify sentence segmentation, we're releasing [`wtpsplit`](https://github.com/bminixhofer/wtpsplit), a Python library implementing the methods from this blog post and [the paper](https://example.com). Our models cover 85 languages and include adapation modules to popular sentence styles to enable multilingual, adapative, punctuation-agnostic, self-supervised sentence segmentation.