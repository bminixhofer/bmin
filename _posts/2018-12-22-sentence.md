---
layout: distill
title: Sentence Segmentation and Why It Matters
description: Accompanying the paper &quot;<a href='https://example.com'>Where’s the Point? Self-Supervised Multilingual Punctuation-Agnostic Sentence Segmentation</a>&quot; with Jonas Pfeiffer and Ivan Vulić, accepted at ACL 2023.
giscus_comments: false
date: 2021-05-22

bibliography: 2018-12-22-distill.bib

# Optionally, you can add a table of contents to your post.
# NOTES:
#   - make sure that TOC names match the actual section names
#     for hyperlinks within the post to work correctly.
#   - we may want to automate TOC generation in the future using
#     jekyll-toc plugin (https://github.com/toshimaru/jekyll-toc).
# toc:
#   - name: Equations
#     # if a section has subsections, you can add them as follows:
#     # subsections:
#     #   - name: Example Child Subsection 1
#     #   - name: Example Child Subsection 2
#   - name: Citations
#   - name: Footnotes
#   - name: Code Blocks
#   - name: Interactive Plots
#   - name: Layouts
#   - name: Other Typography?

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

{% include blog/sentence/prelude.html %}
{% include blog/sentence/main.html %}

Sentences are fundamental to written language. Naturally, Natural Language Processing often involves sentences. For example, the original BERT did Next *Sentence* Prediction, creation of the C4 corpus involved removing "any page with fewer than 5 *sentences*" and datasets such as MultiNLI consist of annotated *sentence* pairs. In fact, around 72% of the papers in the ACL Anthology contain the word "sentence" (~16% in the abstract). However, many of these say do not say mean by "sentence". As usual, BERT is a standout by containing the following admission:

> Throughout this work, a “sentence” can be an arbitrary span of contiguous text, rather than an actual linguistic sentence.

Why do the authors concede all linguistic meaning of a sentence? And what do others mean when they say "sentence"? Like all things involving natural language, it's complicated. Attempts to define sentences go back at least 130 years to Henry Sweet's now-copied-all-over-textbooks definition<d-cite key="sweet2014new"></d-cite>:

> A sentence is a word or group of words capable of expressing a complete thought or meaning.

This definition is not really workable. It moves the problem to another term — what is a complete thought? There are chunks of text which most people would agree are a sentence but hardly convey a complete thought.<d-footnote>For example "Look, having nuclear — my uncle was a great professor and scientist and engineer, Dr. John Trump at MIT; good genes, very good genes, OK, very smart, the Wharton School of Finance, very good, very smart — you know, if you’re a conservative Republican, if I were a liberal, if, like, OK, if I ran as a liberal Democrat, they would say I'm one of the smartest people anywhere in the world — it’s true! — but when you're a conservative Republican they try — oh, do they do a number — that’s why I always start off: Went to Wharton, was a good student, went there, went there, did this, built a fortune — you know I have to give my like credentials all the time, because we’re a little disadvantaged — but you look at the nuclear deal, the thing that really bothers me — it would have been so easy, and it’s not as important as these lives are — nuclear is so powerful; my uncle explained that to me many, many years ago, the power and that was 35 years ago; he would explain the power of what's going to happen and he was right, who would have thought? — but when you look at what's going on with the four prisoners — now it used to be three, now it’s four — but when it was three and even now, I would have said it's all in the messenger; fellas, and it is fellas because, you know, they don't, they haven’t figured that the women are smarter right now than the men, so, you know, it’s gonna take them about another 150 years — but the Persians are great negotiators, the Iranians are great negotiators, so, and they, they just killed, they just killed us, this is horrible." via <a href="https://www.snopes.com/fact-check/donald-trump-sentence">https://www.snopes.com/fact-check/donald-trump-sentence.</a></d-footnote> As such, when someone refers to "sentences" in NLP, they usually mean one of two things:

1. A chunk of text that resulted from instructing annotators to create a sentence, or to segment an existing text into sentences ("ground-truth sentences").
2. Predicted sentences from an automatic sentence segmentation tool, such as Punkt. Many of these are trained on ground-truth sentences.

The MultiNLI corpus is a collection of the first type. The filtering in the C4 corpus is an example of the second: it wouldn't be feasible to manually segment a large portion of the web into sentences. 

At first glance, it seems like we're good. If it's feasible, use ground-truth sentences created by human annotators. If not, approximate the ground-truth with an automatic sentence segmentation tool. But there are some problems.

__"Ground-truth" sentence boundaries are not objectively true.__

{% include blog/sentence/styles.html %}

__It is hard to acquire ground-truth sentences for the long tail of low-resource languages.__

__Existing sentence segmentation tools rely on punctuation.__