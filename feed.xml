<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://bmin.ai/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bmin.ai/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-05-06T16:06:20+00:00</updated><id>https://bmin.ai/feed.xml</id><title type="html">Benjamin Minixhofer</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Sentence Segmentation and Why It Matters</title><link href="https://bmin.ai/preview/sentence/" rel="alternate" type="text/html" title="Sentence Segmentation and Why It Matters" /><published>2021-05-22T00:00:00+00:00</published><updated>2021-05-22T00:00:00+00:00</updated><id>https://bmin.ai/preview/sentence</id><content type="html" xml:base="https://bmin.ai/preview/sentence/"><![CDATA[<style>
d-title {
  padding-top: 4rem;
}
</style>

<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

<script src="https://cdn.quilljs.com/1.3.7/quill.min.js"></script>

<script>
    const Inline = Quill.import("blots/inline");

    const CACHE_SIZE = 1000;
    const CACHE_QUEUE = [];
    const CACHE = {};

    class SplitBlot extends Inline {
        static blotName = "split";
        static tagName = "span";
        constructor(domNode, value) {
            super(domNode, value);
            if (typeof value === "object") {
                this.domNode.dataset.guid = value.guid;
                if (value.selectedStyle) {
                    this.domNode.dataset.style = value.selectedStyle;
                }
            }
        }

        static create() {
            const node = super.create();
            node.classList.add("split");
            return node;
        }

        static formats(node) {
            return node.dataset.guid;
        }
    }
    Quill.register(SplitBlot);

    // see https://github.com/quilljs/quill/issues/2312#issuecomment-426221880
    Inline.order.splice(Inline.order.indexOf("bold"), 0, name);

    async function getEmbeddings(url) {
        return await fetch(url).then((response) => {
            return response.arrayBuffer();
        }).then((buffer) => {
            let view = new DataView(buffer);
            let numBuckets = view.getInt32(0, true);
            let numHashes = view.getInt32(4, true);
            let hashDim = (view.byteLength - 8) / (numBuckets * numHashes) / 4;

            let embeddings = [...Array(numHashes)].map(() => []);
            for (let i = 0; i < numBuckets; i++) {
                for (let j = 0; j < numHashes; j++) {
                    let offset = 8 + (i * numHashes + j) * hashDim * 4;
                    let data = new Float32Array(buffer, offset, hashDim);
                    embeddings[j].push(data);
                }
            }

            return embeddings;
        });
    }

    async function getClf(url) {
        return await fetch(url).then((response) => {
            return response.arrayBuffer();
        }).then((buffer) => {
            let view = new DataView(buffer);
            let nCoefs = buffer.byteLength / 8 - 2;
            let intercept = view.getFloat64(0, true);
            let threshold = view.getFloat64((nCoefs + 1) * 8, true);

            let coefs = [];

            for (let i = 0; i < nCoefs; i++) {
                let coef = view.getFloat64((i + 1) * 8, true);
                coefs.push(coef);
            }

            return {
                coefs: coefs,
                intercept: intercept,
                threshold: threshold
            };
        });
    }

    async function getModel() {
        const [embeddings, session, udClf, opus100Clf, ersatzClf] = await Promise.all([
            getEmbeddings("/assets/blog/sentence/embeddings.bin"),
            ort.InferenceSession.create('/assets/blog/sentence/model.onnx'),
            getClf("/assets/blog/sentence/en_ud_embeddings.bin"),
            getClf("/assets/blog/sentence/en_opus100_embeddings.bin"),
            getClf("/assets/blog/sentence/en_ersatz_embeddings.bin"),
        ]);

        return {
            embeddings: embeddings,
            session: session,
            udClf: udClf,
            opus100Clf: opus100Clf,
            ersatzClf: ersatzClf
        };
    }

    const model = getModel();

    // use an async context to call onnxruntime functions.

    const _PRIMES = [31, 43, 59, 61, 73, 97, 103, 113, 137, 149, 157, 173, 181, 193, 211, 223];

    function embed(text, embeddings) {
        let numBuckets = embeddings[0].length;
        let numHashes = embeddings.length;
        let hashDim = embeddings[0][0].length;

        let result = new Float32Array(text.length * numHashes * hashDim);
        for (let i = 0; i < text.length; i++) {
            for (let j = 0; j < numHashes; j++) {
                let hash = ((text.charCodeAt(i) + 1) * _PRIMES[j]) % numBuckets;

                for (let k = 0; k < hashDim; k++) {
                    result[i * numHashes * hashDim + j * hashDim + k] = embeddings[j][hash][k];
                }
            }
        }

        return {
            data: result,
            dim: numHashes * hashDim
        };
    }

    function sigmoid(x) {
        return 1 / (1 + Math.exp(-x));
    }

    async function infer(text, model, selectedStyle) {
        let cacheKey = text + selectedStyle;

        if (CACHE[cacheKey]) {
            return CACHE[cacheKey];
        }
 
        let maxLength = 512;
        let stride = 256;
    
        const counts = new Int32Array(text.length);
        const newlineProbs = new Float32Array(text.length);
        const udProbs = new Float32Array(text.length);
        const opus100Probs = new Float32Array(text.length);
        const ersatzProbs = new Float32Array(text.length);
        
        let start = 0;
        let end = 0;
        while (end < text.length) {
            end = Math.min(start + maxLength, text.length);
            start = Math.max(0, end - maxLength);

            let sampleText = text.slice(start, end);

            const emb = embed(sampleText, (await model).embeddings);
            const tensorInputsEmbeds = new ort.Tensor('float32', emb.data, [1, sampleText.length, emb.dim]);

            // prepare feeds. use model input names as keys.
            const feeds = { inputs_embeds: tensorInputsEmbeds };

            // feed inputs and run
            const results = await (await model).session.run(feeds);

            // read from results
            const logits = results.logits.data;
            const dim = results.logits.dims[results.logits.dims.length - 1];

            for (let i = 0; i < sampleText.length; i++) {
                let globalI = start + i;

                newlineProbs[globalI] = sigmoid(logits[dim * i]);
                counts[globalI] += 1;

                udProbs[globalI] = (await model).udClf.intercept;
                for (let j = 0; j < dim; j++) {
                    udProbs[globalI] += logits[dim * i + j] * (await model).udClf.coefs[j];
                }

                udProbs[globalI] = sigmoid(udProbs[globalI]);

                opus100Probs[globalI] = (await model).opus100Clf.intercept;
                for (let j = 0; j < dim; j++) {
                    opus100Probs[i] += logits[dim * i + j] * (await model).opus100Clf.coefs[j];
                }
                opus100Probs[globalI] = sigmoid(opus100Probs[globalI]);

                ersatzProbs[globalI] = (await model).ersatzClf.intercept;
                for (let j = 0; j < dim; j++) {
                    ersatzProbs[globalI] += logits[dim * i + j] * (await model).ersatzClf.coefs[j];
                }
                ersatzProbs[globalI] = sigmoid(ersatzProbs[globalI]);
            }
            start += stride;
        }

        // normalize probs
        for (let i = 0; i < text.length; i++) {
            newlineProbs[i] /= counts[i];
            udProbs[i] /= counts[i];
            opus100Probs[i] /= counts[i];
            ersatzProbs[i] /= counts[i];
        }

        let out;

        if (selectedStyle == "ud") {
            out = {
                probs: udProbs,
                threshold: (await model).udClf.threshold
            };
        } else if (selectedStyle == "opus100") {
            out = {
                probs: opus100Probs,
                threshold: (await model).opus100Clf.threshold
            };
        } else if (selectedStyle == "ersatz") {
            out = {
                probs: ersatzProbs,
                threshold: (await model).ersatzClf.threshold
            };
        } else {
            out = {
                probs: newlineProbs,
                threshold: 0.01
            };
        }

        CACHE[cacheKey] = out;
        CACHE_QUEUE.push(cacheKey);

        if (CACHE_QUEUE.length > CACHE_SIZE) {
            delete CACHE[CACHE_QUEUE.shift()];
        }

        return out;
    }

    function registerDemo(name, options) {
        let selectedStyle = null;

        window.addEventListener("load", () => {
            const quill = new Quill(name + "-quill", {
                modules: {
                    toolbar: null,
                    history: {
                        userOnly: true,
                    },
                },
                formats: ["split"],
            });
            quill.root.setAttribute("spellcheck", false);
            
            // see https://github.com/quilljs/quill/issues/110#issuecomment-461591218
            delete quill.getModule("keyboard").bindings["9"];

            function getText() {
                return Array.from(quill.container.querySelectorAll("p"))
                    .map((el) => el.textContent)
                    .join("\n");
            }

            let predict_timeout = null;
            let predict_delta = 300;

            async function populate(text, thresholdOverride) {
                const inference = await infer(text, model, selectedStyle);
                const probs = inference.probs;
                const threshold = thresholdOverride != null ? thresholdOverride : inference.threshold;

                if (getText() != text) {
                    // split is not valid anymore
                    return;
                }

                quill.formatText(0, text.length, { split: false }, "api");

                let offset = 0;
                probs[text.length - 1] = 1.0;
                for (let i = 0; i < text.length; i++) {
                    if (probs[i] > threshold) {
                        let length = i - offset + 1;

                        quill.formatText(offset, length, {
                            "split": {
                                guid: `${offset}_${length}`,
                                selectedStyle: selectedStyle
                            },
                        }, "api");
                        offset = i + 1;
                    }
                }
            }

            quill.on("text-change", async (delta, oldDelta, user) => {
                let text = getText();

                document.querySelector(name + " .clear-button").disabled = text == "";
                document.querySelector(name + " .example-button").disabled = text == options.exampleText;

                if (user === "api") {
                    return;
                }

                quill.formatText(0, text.length, { split: false });

                clearTimeout(predict_timeout);
                predict_timeout = setTimeout(() => {
                    populate(text);
                }, predict_delta);
            });

            document.querySelector(name + " .example-button").addEventListener("click", () => {
                quill.setText(options.exampleText, "api");
                setTimeout(() => {
                    populate(options.exampleText);
                });
            });
            document.querySelector(name + " .clear-button").addEventListener("click", () => {
                quill.setText("", "user");
            });

            if (options.enableThreshold) {
                element = document.querySelector(name + " #newline-prob-threshold");

                function updateThreshold(element) {
                    let temperature = 9.787;
                    let range = Math.exp(temperature);
                    let minValue = Math.exp(0);
                    let value = (Math.exp(element.value / 100 * temperature) - minValue) / range;

                    setTimeout(() => {
                        document.querySelector(name + " #newline-prob-value").textContent = (value * 100).toFixed(3) + "%";
                        populate(getText(), value);
                    });
                }

                element.addEventListener("input", function() {
                    quill.blur();
                    updateThreshold(this);
                });
                updateThreshold(element);
            }

            if (options.enablePunct) {
                selectedStyle = "ud";
                function styleStyle() {
                    document.querySelector(name + " .ud-button").classList.remove("selected-button");
                    document.querySelector(name + " .opus100-button").classList.remove("selected-button");
                    document.querySelector(name + " .ersatz-button").classList.remove("selected-button");
                
                    if (selectedStyle == "ud") {
                        document.querySelector(name + " .ud-button").classList.add("selected-button");
                    }
                    if (selectedStyle == "opus100") {
                        document.querySelector(name + " .opus100-button").classList.add("selected-button");
                    }
                    if (selectedStyle == "ersatz") {
                        document.querySelector(name + " .ersatz-button").classList.add("selected-button");
                    }
                }
                styleStyle();
                document.querySelector(name + " .ud-button").addEventListener("click", () => {
                    selectedStyle = "ud";
                    styleStyle();
                    setTimeout(() => {
                        populate(getText());
                    });
                });
                document.querySelector(name + " .opus100-button").addEventListener("click", () => {
                    selectedStyle = "opus100";
                    styleStyle();
                    setTimeout(() => {
                        populate(getText());
                    });
                });
                document.querySelector(name + " .ersatz-button").addEventListener("click", () => {
                    selectedStyle = "ersatz";
                    styleStyle();
                    setTimeout(() => {
                        populate(getText());
                    });
                });
            }

            quill.setText(options.exampleText, "api");
            populate(options.exampleText);
        });
    }
</script>

<style>
    .caption {
        text-align: center;
        line-height: 1.2rem;
        color: var(--global-text-color-light) !important;
    }

    .editor-container {
        border: 1px solid rgba(0, 0, 0, 0.2);
        border-radius: 5px;
    }

    .punct-line {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 0.5rem;
    }

    .tool-line {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 0.5rem;
        margin-bottom: 1rem;
    }

    .threshold-line {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 0.5rem;
    }

    .distill-button {
        background-color: var(--global-button-color);
        color: var(--global-text-color);
        border-radius: 8px;
        border-width: 0;
        cursor: pointer;
        display: inline-block;
        font-size: 14px;
        font-weight: 500;
        line-height: 20px;
        list-style: none;
        margin: 0;
        padding: 10px 12px;
        text-align: center;
        margin: 0 0.2rem;
    }

    .distill-button:disabled {
        opacity: 0.4;
    }
    
    .distill-button:hover {
        background-color: var(--global-button-color-hover);
    }

    .punct-line .distill-button {
        color: var(--global-text-color);
    }

    .ud-button.selected-button {
        color: white;
        background-color: var(--green-color);
    }

    .opus100-button.selected-button {
        color: white;
        background-color: var(--red-color);
    }

    .ersatz-button.selected-button {
        color: white;
        background-color: var(--blue-color);
    }

    .punct-line .selected-button {
        opacity: 1;
    }

    .model {
        position: relative;
        display: inline-block;
    }

    .model-identifier {
        font-family: monospace;
        color: var(--global-theme-color);
    }

    .split::after {
        position: absolute;
        content: "";
        width: 3px;
        height: 1.3rem;
        background-color: var(--global-theme-color);
    }

    .split[data-style=ud]::after {
        background-color: var(--green-color);
    }

    .split[data-style=opus100]::after {
        background-color: var(--red-color);
    }

    .split[data-style=ersatz]::after {
        background-color: var(--blue-color);
    }

    .split:last-child::after {
        width: 0px;
    }

    .editor-container .ql-editor {
        padding: 1rem 0.5rem;        
        height: auto;
        min-height: 250px;
    }

    .editor-container .ql-editor p {
        font-family: "Roboto", sans-serif;
        font-size: 16.96px;
    }

    .editor-container .ql-editor p::after {
        position: absolute;
        width: 2px;
        height: 1.3rem;
        color:rgba(0, 0, 0, 0.2);
    }

    .editor-container .ql-container {
        height: auto;
    }

    .editor-container #quill-editor {
        height: 250px;
        overflow-y: scroll;
    }
</style>

<link href="//cdn.quilljs.com/1.0.0/quill.snow.css" rel="stylesheet" />

<div id="main-demo" aria-hidden="true">
    <div class="editor-container">
        <p id="main-demo-quill"></p>
    </div>
    <div class="tool-line">
        <div class="model mr-auto">Model: <span class="model-identifier">wtp-bert-tiny</span></div>
        <button class="example-button distill-button">Example Text</button>
        <button class="clear-button distill-button">Clear</button>
    </div>
</div>

<script>
    registerDemo("#main-demo", {
        exampleText: "Click here to play around with sentence segmentation! The best segmentation is often obvious, but in some cases it's not. For example, when they said \"This is a sentence. This is another sentence\", it is not obvious whether the quote should be part of the surrounding sentence, or should itself be split into sentences.\n\nThe model is loaded on the client-side in your browser. It is fast enough to allow live-editing. Check out the Github repository to use it yourself: github.com/bminixhofer/wtpsplit."
    });
</script>

<p><span id="introduction" style="padding-top: 4.8rem;">Sentences are fundamental to written language.</span> Naturally, Natural Language Processing often involves sentences. For example, the original BERT<d-cite key="devlin-etal-2019-bert"></d-cite> did Next <em>Sentence</em> Prediction, creation of the C4 corpus involved removing “any page with fewer than 5 <em>sentences</em>“<d-cite key="t5"></d-cite> and datasets such as MultiNLI<d-cite key="multinli"></d-cite> consist of annotated <em>sentence</em> pairs. In fact, around 72% of the papers in the ACL Anthology contain the word “sentence” (~16% in the abstract).<d-footnote>Checked using <a href="https://huggingface.co/datasets/ACL-OCL/acl-anthology-corpus">https://huggingface.co/datasets/ACL-OCL/acl-anthology-corpus</a> which as of May 2023 contains the papers until September 2022.</d-footnote> However, many of these say do not say what they mean by “sentence”. BERT stands out by containing the following admission:</p>

<blockquote>
  <p>Throughout this work, a “sentence” can be an arbitrary span of contiguous text, rather than an actual linguistic sentence.</p>
</blockquote>

<p>Why do the authors concede all linguistic meaning of a sentence? And what do others mean when they say “sentence”? It’s complicated. Attempts to define sentences go back at least 130 years to Henry Sweet’s now-copied-all-over-textbooks definition<d-cite key="sweet2014new"></d-cite>:</p>

<blockquote>
  <p>A sentence is a word or group of words capable of expressing a complete thought or meaning.</p>
</blockquote>

<p>This definition is not really workable. It moves the problem to another term — what is a complete thought? There are chunks of text which most people would probably agree make up a sentence, but hardly convey a complete thought.<d-footnote>For example "Hey!", or "Look out!", or this notoriously jumbled sentence: <a href="https://www.snopes.com/fact-check/donald-trump-sentence">https://www.snopes.com/fact-check/donald-trump-sentence.</a></d-footnote> As such, when someone refers to “sentences” in NLP, they usually mean one of two things:</p>

<ol>
  <li>A chunk of text that resulted from instructing annotators to create a sentence, or to segment an existing text into sentences (“ground-truth sentences”).</li>
  <li>Predicted sentences from an automatic sentence segmentation tool, such as Punkt<d-cite key="punkt"></d-cite>. Many of these are trained on ground-truth sentences.</li>
</ol>

<p>The MultiNLI corpus is a collection of the first type. The filtering in the C4 corpus is an example of the second: it wouldn’t be feasible to manually segment a large portion of the web into sentences.</p>

<p>At first glance, it seems like we’re good. If it’s feasible, use ground-truth sentences created by human annotators. If not, approximate the ground-truth with an automatic sentence segmentation tool. But there are some problems.</p>

<p><strong>“Ground-truth” sentence boundaries are not objectively true.</strong></p>

<p>Many things involving language are subjective. It might seem like something as fundamental as sentence segmentation could  at least be solved objectively, but alas! There is plenty of room for interpretation in what to consider one sentence. Does nesting via quotation marks constitute a sentence boundary? What about parentheses, enumerations, colons, and semicolons? Different collections of sentences will have different styles of segmentation. <d-footnote>Style can also vary within a collection via different annotators or inconsistencies of an individual annotator.</d-footnote></p>

<style>
td {
    line-height: 1.5rem;
}
</style>

<table>
  <thead>
    <tr>
      <th><strong>Collection</strong></th>
      <th style="text-align: left"><strong>Sentences</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>UD</td>
      <td style="text-align: left"><span class="split" data-style="ud">This is the high season for tourism;</span><span class="split" data-style="ud"> between December and April few people visit and many tour companies and restaurants close down.</span></td>
    </tr>
    <tr>
      <td>OPUS100</td>
      <td style="text-align: left"><span class="split" data-style="opus100">’I couldn’t help it,’ said Five, in a sulky tone; ’Seven jogged my elbow.’</span><span class="split" data-style="opus100">  On which Seven looked up and said, ’That’s right, Five! Always lay the blame (…)!’</span></td>
    </tr>
    <tr>
      <td>Ersatz</td>
      <td style="text-align: left"><span class="split" data-style="ersatz">A lot of people would like to go back to 1970,” before program trading, he said.</span><span class="split" data-style="ersatz"> “I would like to go back to 1970.</span><span class="split" data-style="ersatz"> But we’re not going back (…)”</span></td>
    </tr>
  </tbody>
</table>

<p class="caption">Sentences in the UD<d-cite key="ud"></d-cite>, OPUS100<d-cite key="opus100"></d-cite> and Ersatz<d-cite key="ersatz"></d-cite> collections look noticeably different from each other.</p>

<p><strong>It’s hard to acquire ground-truth sentences for low-resource languages.</strong></p>

<p>Like any kind of labelled data, it’s hard to get ground-truth sentences for the long tail of low-resource languages, which makes it hard to create sentence segmentation tools for these languages.</p>

<p><strong>Existing sentence segmentation tools rely on punctuation.</strong></p>

<p>Existing sentence segmentation tools like Punkt and Ersatz<d-cite key="ersatz"></d-cite> rely on punctuation by treating sentence segmentation as a <em>disambiguation</em> task. They look at all punctuation characters in the text, and for each one, decide whether it constitutes a sentence boundary or not. This is a reasonable approach, but it falls apart in some cases. If a text is missing punctuation, it can not be segmented. Also, text in languages which do not use punctuation (most prominently Thai) can not be segmented.</p>

<blockquote>
  <p>English: Many sentence segmentation tools rely on punctuation. That can be a problem in Thai.</p>

  <p>Thai: เครื่องมือแบ่งส่วนประโยคจำนวนมากใช้เครื่องหมายวรรคตอน นั่นอาจเป็นปัญหาในภาษาไทย</p>

</blockquote>

<hr class="my-3" />

<p>We tried to solve these issues by creating a <em>punctuation-agnostic</em>, <em>adaptible</em> sentence segmentation tool which can be trained without any ground-truth sentences via self-supervision.</p>

<h2 id="self-supervised-sentence-segmentation">Self-Supervised Sentence Segmentation</h2>

<p>Our key insight is that a model which is good at predicting the probability for a <strong>new line (\n)</strong> to occur after any character can segment text into sentences. This could be a decoder-style model à la GPT<d-cite key="gpt"></d-cite> trained on next-character prediction. We use an encoder-style model trained with a newline-corruption method instead to use context from both sides of every character.<d-footnote>Details in <a href="https://example.com">Section 3 of the paper.</a></d-footnote> Like pretraining GPT models, this does not require any labelled data; it’s just language modelling.</p>

<p>The model learns how likely it is for any character to be followed by a new line. The predicted <em>newline probability</em> characterizes sentence boundaries: a new line can never occur within a sentence, while at the same time, a new line can generally occur after any sentence. This allows us to define sentences in a much more concrete way.</p>

<blockquote>
  <p>Tired: A sentence is a word or group of words capable of expressing a complete thought or meaning.</p>

  <p>Wired: <strong style="color: var(--global-theme-color);">A sentence is any sequence of characters which could plausibly be followed by a newline.</strong></p>
</blockquote>

<p>Admittedly, the word “plausibly” still does a lot of heavy lifting here: we need a probability threshold to decide when to count a character as “plausibly followed by a newline”. However, this threshold can just be set to a small constant value like 1%, where different thresholds give rise to different sets of sentences.</p>

<div id="threshold-demo" aria-hidden="true">
    <div class="threshold-line">
        <label for="newline-prob-threshold" class="form-label mb-0">Newline Probability Threshold:</label>
        <input type="range" style="max-width: 10rem;" min="2" max="100" value="53" step="1" class="ml-auto mx-2 custom-range" id="newline-prob-threshold" />
        <span style="width: 4rem;" id="newline-prob-value"></span>
    </div>
    <div class="editor-container">
        <p id="threshold-demo-quill"></p>
    </div>
    <div class="tool-line">
        <div class="model mr-auto">Model: <span class="model-identifier">wtp-bert-tiny</span></div>
        <button class="example-button distill-button">Example Text</button>
        <button class="clear-button distill-button">Clear</button>
    </div>
    <p class="caption">Play around with the newline probability threshold determining sentence boundaries.</p>
</div>

<script>
    registerDemo("#threshold-demo", {
        exampleText: "Click here to play around with sentence segmentation! The best segmentation is often obvious, but in some cases it's not. For example, when they said \"This is a sentence. This is another sentence\", it is not obvious whether the quote should be part of the surrounding sentence, or should itself be split into sentences.\n\nThe model is loaded on the client-side in your browser. It is fast enough to allow live-editing. Check out the Github repository to use it yourself: github.com/bminixhofer/wtpsplit.",
        enableThreshold: true
    });
</script>

<style>
    #threshold-demo {
        position: relative;
        margin-bottom: 1rem;
    }

    @media (min-width: 992px) {
        #threshold-demo .caption {
            position: absolute;
            top: calc(50% - 1rem);
            left: calc(100% + 1rem);
            transform: translateY(-50%);
            text-align: left !important;
            width: 8.5rem;
        }
    }
</style>

<p>In addition to not requiring any ground-truth sentences, this approach does not rely on punctuation, since we treat punctuation like any other character.</p>

<p>But the problem of adaptability still remains. To solve this, we introduced an extension to the newline-prediction objective where we also predict the probability of punctuation characters like commas, dots, and quotation marks. This allows us to adapt the model to different styles of segmentation by learning a logistic regression over punctuation probabilities on a small amount of ground-truth sentences in the desired style of segmentation.<d-footnote>Details in <a href="https://example.com">Section 3.1 of the paper.</a></d-footnote></p>

<div id="styles-demo" aria-hidden="true">
    <div class="punct-line">
        <span class="ml-auto">Style: </span>
        <button class="ud-button distill-button">UD</button>
        <button class="opus100-button distill-button">OPUS100</button>
        <button class="ersatz-button distill-button">Ersatz</button>
    </div>
    <div class="editor-container">
        <p id="styles-demo-quill"></p>
    </div>
    <div class="tool-line">
        <div class="model mr-auto">Model: <span class="model-identifier">wtp-bert-tiny</span></div>
        <button class="example-button distill-button">Example Text</button>
        <button class="clear-button distill-button">Clear</button>
    </div>
    <p class="caption">A small adaptation module allows adapting to different sentence styles. Try out how the same piece of text may be segmented in different collections.</p>
</div>

<script>
    registerDemo("#styles-demo", {
        enablePunct: true,
        exampleText: "This is the high season for tourism; between December and April few people visit and many tour companies and restaurants close down.\n\n’I couldn’t help it,’ said Five, in a sulky tone; ’Seven jogged my elbow.’ On which Seven looked up and said, ’That’s right, Five! Always lay the blame on others.’\n\n\"A lot of people would like to go back to 1970,\" before program trading, he said. \"I would like to go back to 1970. But we’re not going back to 1970.\""
    });
</script>

<style>
    #styles-demo {
        position: relative;
        margin-bottom: 1rem;
    }

    @media (min-width: 992px) {
        #styles-demo .caption {
            position: absolute;
            top: calc(50% - 1rem);
            left: calc(100% + 1rem);
            transform: translateY(-50%);
            text-align: left !important;
            width: 8.5rem;
        }
    }
</style>

<p>Why not just fine-tune the entire model? By learning only a handful of coefficients, the adaptation is more lightweight (127 parameters in our models) and interpretable (since every coefficient corresponds to a character).</p>

<h2 id="where-s-the-point">Where's the Point?</h2>

<p>You may now say, this is all well and good, but why bother with sentence segmentation at all? Many of today’s language models are trained on individual sentences. As we’ve seen, different training datasets often give rise to different styles of sentence segmentation. It turns out that although the particular style of sentence segmentation may not be all that important, <em>consistency</em> between training and inference is important. That is, a model trained on a particular style of sentences performs best if text is segmented following the same style at inference time.</p>

<div style="max-height: 40vw; align-items: center; display: flex; justify-content: center">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 768 288" height="288" width="768" xml:space="preserve" preserveAspectRatio="xMidYMid meet" style="font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, Roboto, &quot;Helvetica Neue&quot;, Arial, &quot;Noto Sans&quot;, &quot;Liberation Sans&quot;, sans-serif, &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, &quot;Segoe UI Symbol&quot;, &quot;Noto Color Emoji&quot;;" id="svg2" version="1.1"><metadata id="metadata8"><rdf:RDF><cc:Work rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage" /></cc:Work></rdf:RDF></metadata><defs id="defs6"><clipPath id="clipPath34" clipPathUnits="userSpaceOnUse"><path id="path32" d="M 29.878125,29.8 H 557.53769 V 204.51416 H 29.878125 Z" /></clipPath><clipPath id="clipPath44" clipPathUnits="userSpaceOnUse"><path id="path42" d="M 29.878125,29.8 H 557.53769 V 204.51416 H 29.878125 Z" /></clipPath><clipPath id="clipPath54" clipPathUnits="userSpaceOnUse"><path id="path52" d="M 29.878125,29.8 H 557.53769 V 204.51416 H 29.878125 Z" /></clipPath><clipPath id="clipPath64" clipPathUnits="userSpaceOnUse"><path id="path62" d="M 29.878125,29.8 H 557.53769 V 204.51416 H 29.878125 Z" /></clipPath><clipPath id="clipPath74" clipPathUnits="userSpaceOnUse"><path id="path72" d="M 29.878125,29.8 H 557.53769 V 204.51416 H 29.878125 Z" /></clipPath></defs><g transform="matrix(1.3333333,0,0,-1.3333333,0,288)" id="g10"><path id="path12" style="fill:#ffffff;fill-opacity:0;fill-rule:nonzero;stroke:none" d="M 0,0 H 576 V 216 H 0 Z" /><path id="path14" style="fill:#ffffff;fill-opacity:0;fill-rule:nonzero;stroke:none" d="M 29.878125,29.8 H 557.53769 V 204.51416 H 29.878125 Z" /><g transform="translate(272.80166,14.346875)" id="g16"><text id="text20" style="font-size:16px;fill:var(--global-text-color);fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan18" y="0" x="0 10.672 19.568001 30.24">BLEU</tspan></text>
</g><g transform="rotate(90,-27.748853,50.251978)" id="g22"><text id="text26" style="font-size:16px;fill:var(--global-text-color);fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan24" y="0" x="0 10.672 19.568001 28.464001 41.792 50.688 59.584 64.031998 72.928001">Segmenter</tspan></text>
</g><g id="g28"><g clip-path="url(#clipPath34)" id="g30"><path id="path36" style="fill:#FF3636;fill-opacity:1;fill-rule:nonzero;stroke:#ffffff;stroke-width:0;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" d="M 29.878125,37.741553 H 532.41104 V 71.17967 H 29.878125 Z" /></g></g><g id="g38"><g clip-path="url(#clipPath44)" id="g40"><path id="path46" style="fill:#0096FF;fill-opacity:1;fill-rule:nonzero;stroke:#ffffff;stroke-width:0;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" d="M 29.878125,79.539199 H 501.671 V 112.97732 H 29.878125 Z" /></g></g><g id="g48"><g clip-path="url(#clipPath54)" id="g50"><path id="path56" style="fill:#a9a9a9;fill-opacity:1;fill-rule:nonzero;stroke:#ffffff;stroke-width:0;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" d="M 29.878125,121.33685 H 386.72996 v 33.43811 H 29.878125 Z" /></g></g><g id="g58"><g clip-path="url(#clipPath64)" id="g60"><path id="path66" style="fill:#808080;fill-opacity:1;fill-rule:nonzero;stroke:#ffffff;stroke-width:0;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" d="M 29.878125,163.13449 H 334.60553 v 33.43812 H 29.878125 Z" /></g></g><g id="g68"><g clip-path="url(#clipPath74)" id="g70"><path id="path76" style="fill:none;stroke:var(--global-text-color);stroke-width:1.5;stroke-linecap:butt;stroke-linejoin:round;stroke-miterlimit:10;stroke-dasharray:5.55, 2.4;stroke-dashoffset:0;stroke-opacity:1" d="M 552.4589,29.8 V 204.51416" /></g></g><g id="g78"><path id="path80" style="fill:none;stroke:var(--global-text-color);stroke-width:0.80000001;stroke-linecap:square;stroke-linejoin:miter;stroke-miterlimit:10;stroke-dasharray:none;stroke-opacity:1" d="M 29.878125,29.8 V 204.51416" /><g transform="translate(454.89267,192.39285)" id="g82"><text id="text86" style="font-size:16px;fill:var(--global-text-color);fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan84" y="0" x="0 12.448 17.775999 26.672001 35.568001 44.464001 53.360001 57.526749 66.709 72.037003 80.932999 85.380997">Ground Truth</tspan></text>
</g><g transform="translate(498.99795,48.190964)" id="g88"><text id="text92" style="font-variant:normal;font-weight:bold;font-size:16px;font-family:Arial;-inkscape-font-specification:Arial-BoldMT;writing-mode:lr-tb;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan90" y="0" x="0 8.8959999 17.792 22.24">37.6</tspan></text>
</g><g transform="translate(36.560744,48.190964)" id="g94"><text id="text98" style="font-size:16px;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan96" y="0" x="0 12.448 21.344 26.672001">Ours</tspan></text>
</g><g transform="translate(468.25791,89.988611)" id="g100"><text id="text104" style="font-variant:normal;font-weight:bold;font-size:16px;font-family:Arial;-inkscape-font-specification:Arial-BoldMT;writing-mode:lr-tb;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan102" y="0" x="0 8.8959999 17.792 22.24">35.3</tspan></text>
</g><g transform="translate(36.560744,89.988611)" id="g106"><text id="text110" style="font-size:16px;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan108" y="0" x="0 10.672 16 24 32.896 37.344002 45.344002 49.792 55.119999 70.223999 73.776001 81.776001 89.776001 97.776001 102.224 111.12 120.016 128.912 133.36 144.032 152.92799 160.92799 165.37601 169.82401 174.272 183.168 192.064 200.96001 209.856">Ersatz (Wicks and Post, 2021)</tspan></text>
</g><g transform="translate(353.31687,131.78626)" id="g112"><text id="text116" style="font-variant:normal;font-weight:bold;font-size:16px;font-family:Arial;-inkscape-font-specification:Arial-BoldMT;writing-mode:lr-tb;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan114" y="0" x="0 8.8959999 17.792 22.24">26.7</tspan></text>
</g><g transform="translate(36.560744,131.78626)" id="g118"><text id="text122" style="font-size:16px;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan120" y="0" x="0 11.552 20.448 24.896 32.896">Naïve</tspan></text>
</g><g transform="translate(301.19244,173.5839)" id="g124"><text id="text128" style="font-variant:normal;font-weight:bold;font-size:16px;font-family:Arial;-inkscape-font-specification:Arial-BoldMT;writing-mode:lr-tb;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan126" y="0" x="0 8.8959999 17.792 22.24">22.8</tspan></text>
</g><g transform="translate(36.560744,173.5839)" id="g130"><text id="text134" style="font-size:16px;fill:#ffffff;fill-opacity:1;fill-rule:nonzero;stroke:none" transform="scale(1,-1)"><tspan id="tspan132" y="0" x="0 11.552 20.448 29.344">None</tspan></text>
</g></g></g></svg>
</div>

<p class="caption">Impact on BLEU score<d-cite key="bleu"></d-cite> of using our method to match sentence segmentation to the segmentation used during training of a Machine Translation model.<d-footnote>Details in <a href="https://example.com">Section 5 of the paper</a>.</d-footnote></p>

<p>Having said that, there is recent work calling into question whether models (specifically for Machine Translation) should really be trained on individual sentences.<d-cite key="wicks-post-2022-sentence,sun-etal-2022-rethinking"></d-cite> I am not involved enough with Machine Translation to have a qualified opinion about this. I do, however, believe that sentences are sufficiently fundamental to language for there to always be a need for sentence segmentation tools, be it as a way to run inference of sentence-level models, as preprocessing step for datasets or as a user-facing feature.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Sentence segmentation is interesting because it seems simple on the surface, but once you look more deeply, it turns out to be not-so-simple after all. It’s also a textbook case for the immense challenge of multilinguality: for many languages, it’s hard to find even a single ground-truth sentence, not to speak of any other kind of annotated data.</p>

<p>To simplify sentence segmentation, we’re releasing <a href="https://github.com/bminixhofer/wtpsplit"><code class="language-plaintext highlighter-rouge">wtpsplit</code></a>, a Python library implementing the methods from this blog post and <a href="https://example.com">the paper</a>. Our models cover 85 languages and include adapation modules to popular sentence styles, enabling multilingual, adapative, punctuation-agnostic, self-supervised sentence segmentation.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Accompanying the paper &quot;Where’s the Point? Self-Supervised Multilingual Punctuation-Agnostic Sentence Segmentation&quot; with Jonas Pfeiffer and Ivan Vulić, accepted at ACL 2023.]]></summary></entry></feed>